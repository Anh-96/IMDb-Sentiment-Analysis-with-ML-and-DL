{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:03.678256Z",
     "start_time": "2026-02-06T11:06:59.930331Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "print(os.listdir(\"../data\"))\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Project\\IMDB\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMDB Dataset.csv']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:03.727762Z",
     "start_time": "2026-02-06T11:07:03.683467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models_path = \"../models/\"\n",
    "X_train, X_test, y_train, y_test = joblib.load(models_path + \"split_data.pkl\")"
   ],
   "id": "50098a43d7ed01ef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:03.750758Z",
     "start_time": "2026-02-06T11:07:03.732022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validation set\n",
    "X_train_dl, X_val_dl, y_train_dl, y_val_dl = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")"
   ],
   "id": "919f1680b8d2d9b6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:06.179569Z",
     "start_time": "2026-02-06T11:07:03.757362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ],
   "id": "546a9ed67a278c7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:06.197052Z",
     "start_time": "2026-02-06T11:07:06.186442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train_num = y_train.map({'positive': 1, 'negative': 0})\n",
    "y_test_num = y_test.map({'positive': 1, 'negative': 0})\n",
    "y_val_num = y_val_dl.map({'positive': 1, 'negative': 0})"
   ],
   "id": "f9f3404611d3c9a7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:12.205550Z",
     "start_time": "2026-02-06T11:07:06.201490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bert_encode(texts, max_len=128):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "X_train_bert = bert_encode(X_train.tolist())\n",
    "X_test_bert = bert_encode(X_test.tolist())\n",
    "X_val_bert = bert_encode(X_val_dl.tolist())"
   ],
   "id": "833f4db6ffcb6911",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:12.213048Z",
     "start_time": "2026-02-06T11:07:12.210212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "id": "e4d5bfb58a056a66",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:12.220046Z",
     "start_time": "2026-02-06T11:07:12.216486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = SentimentDataset(X_train_bert, y_train_num.reset_index(drop=True))\n",
    "test_dataset = SentimentDataset(X_test_bert, y_test_num.reset_index(drop=True))\n",
    "val_dataset = SentimentDataset(X_val_bert, y_val_num.reset_index(drop=True))"
   ],
   "id": "77a50dd15c03fcf8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:13.218403Z",
     "start_time": "2026-02-06T11:07:12.226484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2  # positive and negative\n",
    ")\n",
    "\n",
    "# freeze embeddings\n",
    "# for param in model.bert.embeddings.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Switch the model to GPU if available.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ],
   "id": "7c454e92f5ff8d46",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Loading weights: 0it [00:00, ?it/s]\n",
      "BertForSequenceClassification LOAD REPORT from: distilbert-base-uncased\n",
      "Key                                                                      | Status     | \n",
      "-------------------------------------------------------------------------+------------+-\n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.attention.out_lin.bias   | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.output_layer_norm.weight | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.sa_layer_norm.weight     | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.attention.out_lin.weight | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.attention.k_lin.weight   | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.output_layer_norm.bias   | UNEXPECTED | \n",
      "vocab_layer_norm.weight                                                  | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.ffn.lin2.weight          | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.attention.v_lin.weight   | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.sa_layer_norm.bias       | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.ffn.lin1.weight          | UNEXPECTED | \n",
      "vocab_transform.weight                                                   | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.attention.q_lin.bias     | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.attention.q_lin.weight   | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.ffn.lin2.bias            | UNEXPECTED | \n",
      "distilbert.embeddings.word_embeddings.weight                             | UNEXPECTED | \n",
      "distilbert.embeddings.position_embeddings.weight                         | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.attention.k_lin.bias     | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.ffn.lin1.bias            | UNEXPECTED | \n",
      "vocab_layer_norm.bias                                                    | UNEXPECTED | \n",
      "distilbert.transformer.layer.{0, 1, 2, 3, 4, 5}.attention.v_lin.bias     | UNEXPECTED | \n",
      "distilbert.embeddings.LayerNorm.bias                                     | UNEXPECTED | \n",
      "vocab_projector.bias                                                     | UNEXPECTED | \n",
      "distilbert.embeddings.LayerNorm.weight                                   | UNEXPECTED | \n",
      "vocab_transform.bias                                                     | UNEXPECTED | \n",
      "bert.encoder.layer.{0...11}.attention.self.value.weight                  | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.output.LayerNorm.weight            | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.self.value.bias                    | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.output.dense.bias                  | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.self.query.weight                  | MISSING    | \n",
      "bert.encoder.layer.{0...11}.output.LayerNorm.bias                        | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.self.key.bias                      | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.self.key.weight                    | MISSING    | \n",
      "bert.encoder.layer.{0...11}.output.LayerNorm.weight                      | MISSING    | \n",
      "bert.encoder.layer.{0...11}.intermediate.dense.weight                    | MISSING    | \n",
      "bert.encoder.layer.{0...11}.output.dense.bias                            | MISSING    | \n",
      "bert.encoder.layer.{0...11}.intermediate.dense.bias                      | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.self.query.bias                    | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.output.LayerNorm.bias              | MISSING    | \n",
      "bert.pooler.dense.weight                                                 | MISSING    | \n",
      "bert.encoder.layer.{0...11}.attention.output.dense.weight                | MISSING    | \n",
      "bert.encoder.layer.{0...11}.output.dense.weight                          | MISSING    | \n",
      "bert.embeddings.LayerNorm.weight                                         | MISSING    | \n",
      "classifier.weight                                                        | MISSING    | \n",
      "bert.pooler.dense.bias                                                   | MISSING    | \n",
      "bert.embeddings.LayerNorm.bias                                           | MISSING    | \n",
      "bert.embeddings.position_embeddings.weight                               | MISSING    | \n",
      "classifier.bias                                                          | MISSING    | \n",
      "bert.embeddings.word_embeddings.weight                                   | MISSING    | \n",
      "bert.embeddings.token_type_embeddings.weight                             | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:13.229415Z",
     "start_time": "2026-02-06T11:07:13.223362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_results\",\n",
    "    eval_strategy=IntervalStrategy.STEPS,\n",
    "    eval_steps=500,\n",
    "    save_total_limit=5,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=200,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ],
   "id": "571a79548b7223e7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:13.237420Z",
     "start_time": "2026-02-06T11:07:13.234806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(p):\n",
    "    logits = p.predictions\n",
    "    labels = p.label_ids\n",
    "    pred = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, pred),\n",
    "        \"f1\": f1_score(labels, pred)\n",
    "    }"
   ],
   "id": "d45febc06d611daf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T11:07:13.277408Z",
     "start_time": "2026-02-06T11:07:13.241860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ],
   "id": "9bc0aaea9b7f0c23",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T17:03:25.412809Z",
     "start_time": "2026-02-06T11:07:22.302934Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "dfb36f9d72ed7ef8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 5:56:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.702643</td>\n",
       "      <td>0.694272</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.695013</td>\n",
       "      <td>0.581166</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.687951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.457140</td>\n",
       "      <td>0.785500</td>\n",
       "      <td>0.751160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.453557</td>\n",
       "      <td>0.367975</td>\n",
       "      <td>0.831750</td>\n",
       "      <td>0.843014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.418709</td>\n",
       "      <td>0.404788</td>\n",
       "      <td>0.820250</td>\n",
       "      <td>0.839473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378181</td>\n",
       "      <td>0.331340</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.866157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.362496</td>\n",
       "      <td>0.317839</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>0.863979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.344720</td>\n",
       "      <td>0.333165</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.870774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.346061</td>\n",
       "      <td>0.283556</td>\n",
       "      <td>0.888750</td>\n",
       "      <td>0.889386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.327599</td>\n",
       "      <td>0.275490</td>\n",
       "      <td>0.890750</td>\n",
       "      <td>0.893180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.283436</td>\n",
       "      <td>0.304109</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.879896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.293191</td>\n",
       "      <td>0.274551</td>\n",
       "      <td>0.893500</td>\n",
       "      <td>0.897250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.306048</td>\n",
       "      <td>0.266702</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.892528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.288280</td>\n",
       "      <td>0.264614</td>\n",
       "      <td>0.898500</td>\n",
       "      <td>0.897630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.271006</td>\n",
       "      <td>0.257044</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.902204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "44a7ba7455a32d9443cff818fbf160e3"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n",
      "There were missing keys in the checkpoint model loaded: ['bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['bert.embeddings.LayerNorm.beta', 'bert.embeddings.LayerNorm.gamma', 'bert.encoder.layer.0.attention.output.LayerNorm.beta', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma', 'bert.encoder.layer.0.output.LayerNorm.beta', 'bert.encoder.layer.0.output.LayerNorm.gamma', 'bert.encoder.layer.1.attention.output.LayerNorm.beta', 'bert.encoder.layer.1.attention.output.LayerNorm.gamma', 'bert.encoder.layer.1.output.LayerNorm.beta', 'bert.encoder.layer.1.output.LayerNorm.gamma', 'bert.encoder.layer.2.attention.output.LayerNorm.beta', 'bert.encoder.layer.2.attention.output.LayerNorm.gamma', 'bert.encoder.layer.2.output.LayerNorm.beta', 'bert.encoder.layer.2.output.LayerNorm.gamma', 'bert.encoder.layer.3.attention.output.LayerNorm.beta', 'bert.encoder.layer.3.attention.output.LayerNorm.gamma', 'bert.encoder.layer.3.output.LayerNorm.beta', 'bert.encoder.layer.3.output.LayerNorm.gamma', 'bert.encoder.layer.4.attention.output.LayerNorm.beta', 'bert.encoder.layer.4.attention.output.LayerNorm.gamma', 'bert.encoder.layer.4.output.LayerNorm.beta', 'bert.encoder.layer.4.output.LayerNorm.gamma', 'bert.encoder.layer.5.attention.output.LayerNorm.beta', 'bert.encoder.layer.5.attention.output.LayerNorm.gamma', 'bert.encoder.layer.5.output.LayerNorm.beta', 'bert.encoder.layer.5.output.LayerNorm.gamma', 'bert.encoder.layer.6.attention.output.LayerNorm.beta', 'bert.encoder.layer.6.attention.output.LayerNorm.gamma', 'bert.encoder.layer.6.output.LayerNorm.beta', 'bert.encoder.layer.6.output.LayerNorm.gamma', 'bert.encoder.layer.7.attention.output.LayerNorm.beta', 'bert.encoder.layer.7.attention.output.LayerNorm.gamma', 'bert.encoder.layer.7.output.LayerNorm.beta', 'bert.encoder.layer.7.output.LayerNorm.gamma', 'bert.encoder.layer.8.attention.output.LayerNorm.beta', 'bert.encoder.layer.8.attention.output.LayerNorm.gamma', 'bert.encoder.layer.8.output.LayerNorm.beta', 'bert.encoder.layer.8.output.LayerNorm.gamma', 'bert.encoder.layer.9.attention.output.LayerNorm.beta', 'bert.encoder.layer.9.attention.output.LayerNorm.gamma', 'bert.encoder.layer.9.output.LayerNorm.beta', 'bert.encoder.layer.9.output.LayerNorm.gamma', 'bert.encoder.layer.10.attention.output.LayerNorm.beta', 'bert.encoder.layer.10.attention.output.LayerNorm.gamma', 'bert.encoder.layer.10.output.LayerNorm.beta', 'bert.encoder.layer.10.output.LayerNorm.gamma', 'bert.encoder.layer.11.attention.output.LayerNorm.beta', 'bert.encoder.layer.11.attention.output.LayerNorm.gamma', 'bert.encoder.layer.11.output.LayerNorm.beta', 'bert.encoder.layer.11.output.LayerNorm.gamma'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7500, training_loss=0.41058680114746093, metrics={'train_runtime': 21362.9596, 'train_samples_per_second': 5.617, 'train_steps_per_second': 0.351, 'total_flos': 7893331660800000.0, 'train_loss': 0.41058680114746093, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Consume a lot of times\n",
    "- It's not that high if compare with other model"
   ],
   "id": "4a7647483ea46564"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T17:05:36.685803Z",
     "start_time": "2026-02-06T17:03:25.505197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bert_results = trainer.evaluate()\n",
    "bert_results"
   ],
   "id": "a22be9d061784f61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "73109870ae4e5067eb70b309816d2e87"
     }
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2570444643497467,\n",
       " 'eval_accuracy': 0.90125,\n",
       " 'eval_f1': 0.9022035157217133,\n",
       " 'eval_runtime': 131.1755,\n",
       " 'eval_samples_per_second': 30.494,\n",
       " 'eval_steps_per_second': 1.906,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T17:11:03.356303Z",
     "start_time": "2026-02-06T17:05:36.736064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "print(classification_report(y_test_num, y_pred))\n",
    "cm = confusion_matrix(y_test_num, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ],
   "id": "30822c7901fb11ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84      5000\n",
      "           1       0.84      0.85      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- The accuracy on test set is not that high",
   "id": "5ba4d38245d8a5cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T17:11:03.382806Z",
     "start_time": "2026-02-06T17:11:03.378723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test on some review\n",
    "\n",
    "test_reviews = [\n",
    "    \"It wasn’t what I expected, but I kept thinking about it afterward.\",\n",
    "    \"Some parts felt slow, yet I didn’t really want it to end.\",\n",
    "    \"I’m not sure I liked it, though I can see why others would.\",\n",
    "    \"It had its moments, even if I wouldn’t rush to experience it again.\",\n",
    "    \"Strangely frustrating, but not entirely without charm.\"\n",
    "]\n",
    "\n",
    "test_input = bert_encode(test_reviews)"
   ],
   "id": "6a4ce2f4c26d990",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T17:11:03.574299Z",
     "start_time": "2026-02-06T17:11:03.400393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check test sentiment\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**test_input)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "label_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "pred_labels = [label_map[p.item()] for p in predictions]\n",
    "\n",
    "for review, label in zip(test_reviews, pred_labels):\n",
    "    print(\"Review:\")\n",
    "    print(review)\n",
    "    print(\"Predicted Sentiment:\", label)\n",
    "    print(\"-\" * 50)\n"
   ],
   "id": "9c723cff8d83a09b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:\n",
      "It wasn’t what I expected, but I kept thinking about it afterward.\n",
      "Predicted Sentiment: Negative\n",
      "--------------------------------------------------\n",
      "Review:\n",
      "Some parts felt slow, yet I didn’t really want it to end.\n",
      "Predicted Sentiment: Negative\n",
      "--------------------------------------------------\n",
      "Review:\n",
      "I’m not sure I liked it, though I can see why others would.\n",
      "Predicted Sentiment: Positive\n",
      "--------------------------------------------------\n",
      "Review:\n",
      "It had its moments, even if I wouldn’t rush to experience it again.\n",
      "Predicted Sentiment: Positive\n",
      "--------------------------------------------------\n",
      "Review:\n",
      "Strangely frustrating, but not entirely without charm.\n",
      "Predicted Sentiment: Negative\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T17:11:03.592804Z",
     "start_time": "2026-02-06T17:11:03.589242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check confidence for each reviews\n",
    "probs = torch.softmax(outputs.logits, dim=1)\n",
    "\n",
    "for review, prob in zip(test_reviews, probs):\n",
    "    print(review)\n",
    "    print(\"Positive confidence:\", prob[1].item())\n",
    "    print(\"Negative confidence:\", prob[0].item())\n",
    "    print(\"-\" * 50)\n"
   ],
   "id": "f59e124b7d6227b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It wasn’t what I expected, but I kept thinking about it afterward.\n",
      "Positive confidence: 0.15246401727199554\n",
      "Negative confidence: 0.847536027431488\n",
      "--------------------------------------------------\n",
      "Some parts felt slow, yet I didn’t really want it to end.\n",
      "Positive confidence: 0.011351697146892548\n",
      "Negative confidence: 0.9886483550071716\n",
      "--------------------------------------------------\n",
      "I’m not sure I liked it, though I can see why others would.\n",
      "Positive confidence: 0.8697175979614258\n",
      "Negative confidence: 0.13028238713741302\n",
      "--------------------------------------------------\n",
      "It had its moments, even if I wouldn’t rush to experience it again.\n",
      "Positive confidence: 0.8889837265014648\n",
      "Negative confidence: 0.11101622134447098\n",
      "--------------------------------------------------\n",
      "Strangely frustrating, but not entirely without charm.\n",
      "Positive confidence: 0.013936012051999569\n",
      "Negative confidence: 0.9860639572143555\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Day 9 - BERT\n",
    "- BERT takes a lot of time to train\n",
    "- It not that better than other model but consider the training time"
   ],
   "id": "36726a4a9f019921"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "31534d86f4535c77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
